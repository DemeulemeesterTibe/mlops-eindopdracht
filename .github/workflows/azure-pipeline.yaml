name: MLOPS Azure text sentiment classification pipeline 

on: 
  workflow_dispatch:
    inputs:
      create_compute:
        description: 'Create compute instance'
        required: true
        type: boolean
        default: true
      epochs:
        description: 'Number of epochs to train the model'
        required: true
        type: number
        default: 10

env:
  GROUP: mlops-eindopdracht
  WORKSPACE: eindopdracht
  LOCATION: westeurope

jobs:
  azure-pipeline:
    runs-on: ubuntu-latest
    outputs:
      ai-model: ${{ steps.azure-pipeline.outputs.latest_version }}
    steps:
      - name: 'Checkout out repository'
        uses: actions/checkout@v4

      - name: 'Login via Azure CLI'
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: 'Create compute instance'
        uses: azure/CLI@v1
        id: azure-create-compute
        if: ${{ inputs.create_compute }}
        with:
          azcliversion: 2.53.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml compute create -f ./environment/compute.yaml
      
      - name: 'Start compute instance'
        uses: azure/CLI@v1
        if: ${{ steps.azure-create-compute.outcome == 'skipped' }}
        with:
          azcliversion: 2.53.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml compute start -n mlops-cli
        continue-on-error: true

      - name: 'Run the azure ml pipeline'
        uses: azure/CLI@v1
        id: azure-pipeline
        with:
          azcliversion: 2.53.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml job create --file ./pipelines/text-sentiment.yaml --set name=emotions-classification-${{ github.sha }}-${{ github.run_id }} --stream
            echo "Pipeline is done running"
            VERSION=$(az ml model list -n emotions-classification --query '[0].version')
            echo "Latest version of model is $VERSION"
            echo "::set-output name=latest_version::$VERSION"
        
      - name: 'Stop compute instance'
        uses: azure/CLI@v1
        id: azure-stop-compute
        if: always()
        with:
          azcliversion: 2.53.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml compute stop -n mlops-cli
        continue-on-error: true
            
  download-model:
    runs-on: ubuntu-latest
    needs: azure-pipeline
    if: ${{ needs.azure-pipeline.result == 'success' }} || ${{ needs.azure-pipeline.result == 'skipped' }}
    steps:
      - name: 'Checkout out repository'
        uses: actions/checkout@v4

      - name: 'Az CLI login'
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      
      - name: 'Download model'
        uses: azure/CLI@v1
        with:
          azcliversion: 2.53.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            VERSION=$(az ml model list -n emotions-classification --query '[0].version' -o tsv)
            echo "Latest version of model is $VERSION"
            echo "::set-output name=latest_version::$VERSION"
            az ml model download -n emotions-classification -v $VERSION -d ./inference 
      
      - name: Upload api code
        uses: actions/upload-artifact@v2
        with:
          name: docker-config
          path: inference
    
  # deploy-model:
  #   needs: download-model
  #   runs-on: ubuntu-latest
  #   if: ${{ needs.download-model.result == 'success' }}
  #   steps:

  #     - name: 'Docker metadata'
  #       id: docker-metadata
  #       uses: docker/metadata-action@v3
  #       with:
  #         images: ghcr.io/demeulemeestertibe/mlops-2.0
  #         tags: |
  #           type=ref,event=branch
  #           type=sha
      
  #     - name: Login to GHCR
  #       uses: docker/login-action@v1
  #       with:
  #         registry: ghcr.io
  #         username: ${{ github.repository_owner }}
  #         password: ${{ secrets.TOKEN }}
    
  #     - name: Download API code for Docker
  #       uses: actions/download-artifact@v2
  #       with:
  #         name: docker-config
  #         path: inference

  #     - name: Docker Build and push
  #       id: docker_build
  #       uses: docker/build-push-action@v2
  #       with:
  #         context: ./inference
  #         push: true
  #         tags: ${{ steps.docker-metadata.outputs.tags }}